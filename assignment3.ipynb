{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EkWg3jXFjq3u"
   },
   "source": [
    "<h1>Assignment 3: Group Project</h1>\n",
    "\n",
    "<h3>Movie Rating Prediction system</h3>\n",
    "\n",
    "Group 6 Members:\n",
    "- Vo Thanh Luan (s3822042)\n",
    "- Nguyen Bao Khang (s3817970)\n",
    "- Duong Tuan Dat (s3636739)\n",
    "- Bui Dang Dac Duong (s3764487)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N0yE4RnNkBLw"
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NQSKC61AmNd2"
   },
   "source": [
    "# 1. Data preparation and exploration\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EQp0hNrplT2F"
   },
   "source": [
    "## 1.1 Data Retrieving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-NkJBrydjqbP",
    "outputId": "cc143f9d-7494-4f69-fd1d-14a9caeb05ff"
   },
   "outputs": [],
   "source": [
    "movies_df = pd.read_csv('data/movies.csv', delimiter=',', parse_dates=[\"release_date\"])\n",
    "ratings_df = pd.read_csv('data/ratings.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 722
    },
    "id": "vVjklWtOkrk0",
    "outputId": "05197f78-c4a3-4f1b-b88e-bc3981e5be17"
   },
   "outputs": [],
   "source": [
    "movies_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "Hn8_I64lktIG",
    "outputId": "ff032f63-7842-4dc7-cc00-9fbcc623254b"
   },
   "outputs": [],
   "source": [
    "ratings_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G9irH_sYlfR_"
   },
   "source": [
    "## 1.2 Data cleaning and preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZvyVLEITlCWX"
   },
   "outputs": [],
   "source": [
    "#set threshold\n",
    "threshold = 0.65\n",
    "\n",
    "# dropping columns with missing value rate higher than threshold\n",
    "ratings_df = ratings_df[ratings_df.columns[ratings_df.isnull().mean() < threshold]]\n",
    "\n",
    "# Remove the missing values from the rows having greater or equal to 6 missing values.\n",
    "movies_df = movies_df[movies_df.isnull().sum(axis=1) <= 6]\n",
    "ratings_df = ratings_df[ratings_df.isnull().sum(axis=1) <= 6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TULy-399yDPN"
   },
   "source": [
    "### 1.2.1 Handle missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentage of missing value in movies_df before cleaning\n",
    "percent_missing = movies_df.isnull().sum() * 100 / len(movies_df)\n",
    "missing_values = pd.DataFrame({'percent_missing': percent_missing})\n",
    "missing_values.sort_values(by ='percent_missing' , ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KlAlkZP8qiW6",
    "outputId": "f984ca15-49a5-41de-c1eb-3b3ad42bfcf1"
   },
   "outputs": [],
   "source": [
    "# Filling missing value for movies dataset\n",
    "\n",
    "movies_df[\"tagline\"] = movies_df[\"tagline\"].fillna(\"Unknown\")\n",
    "\n",
    "movies_df[\"overview\"] = movies_df[\"overview\"].fillna(\"Unknown\")\n",
    "\n",
    "movies_df[\"poster_path\"] = movies_df[\"poster_path\"].fillna(\"Unknown\")\n",
    "\n",
    "movies_df[\"runtime\"] = movies_df[\"runtime\"].fillna(method='ffill')\n",
    "\n",
    "movies_df[\"release_date\"] = movies_df[\"release_date\"].fillna(method='ffill')\n",
    "\n",
    "movies_df[\"status\"] = movies_df[\"status\"].fillna(movies_df['status'].mode()[0])\n",
    "\n",
    "movies_df[\"imdb_id\"] = movies_df[\"imdb_id\"].fillna(method='ffill')\n",
    "\n",
    "movies_df[\"original_language\"] = movies_df[\"original_language\"].fillna(movies_df['original_language'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 802
    },
    "id": "QpVzZ0OklZFi",
    "outputId": "c0d95dee-f233-44bc-dea6-a08525bcb1f3"
   },
   "outputs": [],
   "source": [
    "# Percentage of missing value in movies_df after cleaning\n",
    "percent_missing = movies_df.isnull().sum() * 100 / len(movies_df)\n",
    "missing_values = pd.DataFrame({'percent_missing': percent_missing})\n",
    "missing_values.sort_values(by ='percent_missing' , ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "id": "RZzEJzMglw1-",
    "outputId": "11418f2f-3f89-4b7a-acb1-6b1ebc35a60d"
   },
   "outputs": [],
   "source": [
    "# Percentage of missing value in ratings_df before cleaning\n",
    "percent_missing = ratings_df.isnull().sum() * 100 / len(ratings_df)\n",
    "missing_values = pd.DataFrame({'percent_missing': percent_missing})\n",
    "missing_values.sort_values(by ='percent_missing' , ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w251pz1DnEm-"
   },
   "outputs": [],
   "source": [
    "# rename column id in movies_df to match movieId with ratings_df\n",
    "movies_df.rename(columns={\"id\": \"movieId\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oE5GFhHenh9C",
    "outputId": "3669600c-ed62-49d9-b2a2-6d731d916185"
   },
   "outputs": [],
   "source": [
    "# Check type for movies_df\n",
    "movies_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7abYwMOZn-kx",
    "outputId": "e81e7cac-cb48-4238-8503-5cff19b2184c",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check type for ratings_df\n",
    "ratings_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7_N-jHRI7e9f"
   },
   "outputs": [],
   "source": [
    "# Delete row in movieId column contain string value\n",
    "movies_df = movies_df[~movies_df['movieId'].isin(['1997-08-20', '2012-09-29','2014-01-01'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "53otKBkcoKs8"
   },
   "outputs": [],
   "source": [
    "# change column type for movies_df\n",
    "movies_df[\"movieId\"] = pd.to_numeric(movies_df['movieId'])\n",
    "\n",
    "movies_df[\"popularity\"] = pd.to_numeric(movies_df['popularity'])\n",
    "\n",
    "movies_df[\"budget\"] = pd.to_numeric(movies_df['budget'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each movie has many ratings rated by many different users. We calculate the average ratings of one movie by sum all the ratings of one movie and divide by the number of ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wa4ktauuccSJ"
   },
   "outputs": [],
   "source": [
    "ratings_df = ratings_df.groupby(['movieId']).mean().groupby('movieId')['rating'].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VHtlMVJQ9qTk"
   },
   "outputs": [],
   "source": [
    "df = movies_df.merge(ratings_df, how=\"left\", on=\"movieId\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rating'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the number of movies which do not have rating is very high(42621); therefore, we need to handle missing data. In order to do that, we see that in the data frame it has the \"imdb_id\" column. Therefore,we will use that column to crawl the updated data of movie rating in IMDB website. When doing this, we can make sure the movie rating is accurate and updated as well as taking care of missing rating in movies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refer to \"imdb_crawler\" folder , we have created the python script to crawl rating from IMDB website and then we output the updated ratings.csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load new ratings.csv file\n",
    "ratings_updated_df = pd.read_csv(\"imdb_crawler/ratings.csv\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentage of missing value in ratings_updated_df before cleaning\n",
    "percent_missing = ratings_updated_df.isnull().sum() * 100 / len(ratings_updated_df)\n",
    "missing_values = pd.DataFrame({'percent_missing': percent_missing})\n",
    "missing_values.sort_values(by ='percent_missing' , ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the percentage of missing values in rating column is very low (0.05%), we can safely drop the rows with missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_updated_df['rating'] = ratings_updated_df['rating'].dropna(how='any',axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_updated_df = ratings_updated_df.groupby(['movieId']).mean().groupby('movieId')['rating'].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_updated = movies_df.merge(ratings_updated_df, how=\"left\", on=\"movieId\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Round rating float, for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_updated = df_updated.round({'rating': 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if any movies do not have rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_updated['rating'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the number that do not have rating is very small (49) compared to the ammount of movies, therefore, we will delete all the rows contains the movie which do not have rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_updated = df_updated.dropna(subset=['rating'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, we check the number of movies which do not have rating and see that all the movies have its rating now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_updated['rating'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the dataset, there are some columns with array object as values. We would like to convert to array string based on the field name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z93sg8_8QnER"
   },
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "\n",
    "def split_genres(row):\n",
    "    row['genres'] = \",\".join([info['name'] for info in literal_eval(row['genres'])])\n",
    "    return row\n",
    "\n",
    "def split_prod_countries(row):\n",
    "    row['production_countries'] = \",\".join([info['name'] for info in literal_eval(row['production_countries'])])\n",
    "    return row\n",
    "\n",
    "def split_prod_companies(row):\n",
    "    row['production_companies'] = \",\".join([info['name'] for info in literal_eval(row['production_companies'])])\n",
    "    return row\n",
    "\n",
    "def split_spoken_languages(row):\n",
    "    row['spoken_languages'] = \",\".join([info['name'] for info in literal_eval(row['spoken_languages'])])\n",
    "    return row\n",
    "  \n",
    "df_updated = df_updated.apply(split_genres, axis=1)\n",
    "df_updated = df_updated.apply(split_prod_countries, axis=1)\n",
    "df_updated = df_updated.apply(split_prod_companies, axis=1)\n",
    "df_updated = df_updated.apply(split_spoken_languages, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for text cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XBa7szbZsXy2"
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # remove backslash-apostrophe\n",
    "    text = re.sub(\"\\'\", \"\", text)\n",
    "    # remove everything alphabets\n",
    "    text = re.sub(r\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\", \"\", text)\n",
    "    # remove whitespaces\n",
    "    text = ' '.join(text.split())\n",
    "    # remove double quote inside\n",
    "    text = text.replace('“', '').replace('”', '').replace('\"', '')\n",
    "    # remove number\n",
    "    text = re.sub(r\"\\d+\", \"\", text)\n",
    "    # convert text to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply clean_text function for below column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "csod_iXVy8Ia"
   },
   "outputs": [],
   "source": [
    "df_updated['title'] = df_updated['title'].apply(lambda x: clean_text(x))\n",
    "df_updated['tagline'] = df_updated['tagline'].apply(lambda x: clean_text(x))\n",
    "df_updated['original_title'] = df_updated['original_title'].apply(lambda x: clean_text(x))\n",
    "df_updated['overview'] = df_updated['overview'].apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove stopword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RXcMrDQp0uH7",
    "outputId": "64f140ff-683e-4b2b-cd90-478a19401a16"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# function to remove stopwords\n",
    "def remove_stopwords(text):\n",
    "    no_stopword_text = [w for w in text.split() if not w in stop_words]\n",
    "    return ' '.join(no_stopword_text)\n",
    "  \n",
    "df_updated['overview'] = df_updated['overview'].apply(lambda x: remove_stopwords(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create original data frame by copying exising dataframe before doing categorical encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = df_updated.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9JTtBkbyyK-0"
   },
   "source": [
    "**belongs_to_collection**\n",
    "\n",
    "\n",
    "Convert column 'belongs_to_collection' data to binary data of 0 and 1 (1 means the movie belongs to a collection, and 0 means it does not belong to any collection)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SD_d-Dmol1Iv"
   },
   "outputs": [],
   "source": [
    "# converting column 'belongs_to_collection' to binary 0 and 1 data\n",
    "df_updated[\"belongs_to_collection\"] = df_updated[\"belongs_to_collection\"].fillna(0)\n",
    "df_updated[\"belongs_to_collection\"] = np.where(df_updated[\"belongs_to_collection\"] != 0,1,0)\n",
    "df_updated['belongs_to_collection'] = pd.to_numeric(df_updated['belongs_to_collection'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cA4TlA52ycbk"
   },
   "source": [
    "**homepage**\n",
    "\n",
    "Convert column 'homepage' to binary data of 0 and 1 (1 means the movie has a homepage, and 0 means the movie does not have a homepage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JU1rdLn6vjqi"
   },
   "outputs": [],
   "source": [
    "df_updated[\"homepage\"] = df_updated[\"homepage\"].fillna(0)\n",
    "df_updated[\"homepage\"] = np.where(df_updated[\"homepage\"] != 0,1,0)\n",
    "df_updated['homepage'] = pd.to_numeric(df_updated['homepage'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L5CI2Kauy4C4"
   },
   "source": [
    "**adult**\n",
    "\n",
    "Convert column 'adult' data from boolean value to 1 and 0 (1: True, 0: False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JN5uYbW0ypC7"
   },
   "outputs": [],
   "source": [
    "df_updated[\"adult\"] = np.where(df_updated['adult'] == True, 1, 0)\n",
    "df_updated['adult'] = pd.to_numeric(df_updated['adult'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**video**\n",
    "\n",
    "Convert column 'video' data from boolean value to 1 and 0 (1: True, 0: False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_updated[\"video\"] = np.where(df_updated['video'] == True, 1, 0)\n",
    "df_updated['video'] = pd.to_numeric(df_updated['video'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**status**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_updated['status'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since \"Released\" is the dominant value in this column, we can make the dataset easier for computing by replacing value \"Released\" with 1, and the others with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_updated[\"status\"] = np.where(df_updated['status'].str.contains(\"Released\"), 1, 0)\n",
    "df_updated['status'] = pd.to_numeric(df_updated['status'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**spoken_languages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_updated['spoken_languages'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same with column 'status', English is the most common language used in the movies. In addition, it also dominate other languages in terms of quantity. Therefore, we can set value 1 for movies that has English as one of the spoken language, and 0 when the movie does not use English."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_updated[\"spoken_languages\"] = np.where(df_updated['spoken_languages'].str.contains(\"English\"), 1, 0)\n",
    "df_updated['spoken_languages'] = pd.to_numeric(df_updated['spoken_languages'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**original_language**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_updated['original_language'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_updated[\"original_language\"] = np.where(df_updated['original_language'] == \"en\", 1, 0)\n",
    "df_updated['original_language'] = pd.to_numeric(df_updated['original_language'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**production_countries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_updated['production_countries'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From a real world perspective, we can observe that the US's movie industry is gigantic. From this standpoint, we can set value of 1 for movies that involved the US in the production phase, and 0 for ther others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_updated[\"production_countries\"] = np.where(df_updated['production_countries'].str.contains(\"United States of America\"), 1, 0)\n",
    "df_updated['production_countries'] = pd.to_numeric(df_updated['production_countries'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**genres**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_list = []\n",
    "for value in df_updated['genres'].unique():\n",
    "  value_list = value.split(',')\n",
    "  for item in value_list:\n",
    "    genre_list.append(item.strip())\n",
    "\n",
    "genre_list = np.unique(np.array(genre_list)).tolist()\n",
    "genre_list.remove(\"\")\n",
    "\n",
    "for genre in genre_list:\n",
    "  column_name = 'genres_' + genre\n",
    "  df_updated[column_name] = np.where(df_updated['genres'].str.contains(genre), 1, 0)\n",
    "    \n",
    "df_updated.drop(\"genres\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**production_companies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_updated['production_companies'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of over 45k movies, there are x movies that does not have any production company. In this situation, we can perform custom binary encoding for this feature, so that value 1 represents movies that has at least one production company, and reverse, value 0 represents movies that does not have any production company\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_updated[\"production_companies\"] = np.where(df_updated['production_companies'] != \"\", 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_updated['production_companies'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**release_date**\n",
    "\n",
    "To use a datetime feature for fitting into a machine learning model, we can extract cyclical features (day, month) and encode them using sine and cosine transformation. This is to ensure that the data still keeps there cyclinal nature.\n",
    "https://www.kaggle.com/avanwyk/encoding-cyclical-features-for-deep-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(data, col, max_val):\n",
    "    data[col + '_sin'] = np.sin(2 * np.pi * data[col]/max_val)\n",
    "    data[col + '_cos'] = np.cos(2 * np.pi * data[col]/max_val)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_updated['release_date']= pd.to_datetime(df_updated['release_date'])\n",
    "df_updated['month'] = df_updated.release_date.dt.month\n",
    "df_updated['day'] = df_updated.release_date.dt.dayofyear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_updated = encode(df_updated, 'month', 12)\n",
    "df_updated = encode(df_updated, 'day', 365)\n",
    "# drop original unencoded features\n",
    "df_updated.drop(['month', 'day', 'release_date'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LmKNPetCmO5F"
   },
   "source": [
    "## 1.3 Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph 1: Number of Movies produced by a Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 683
    },
    "id": "e4UZCaWOutkJ",
    "outputId": "0bb39109-bbce-46cd-92bf-94ac254b40bc"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "a = []\n",
    "for each in df_raw.production_countries.str.split(\",\"):\n",
    "    for i in each:\n",
    "        a.append(i)\n",
    "        \n",
    "b = dict(Counter(a))\n",
    "\n",
    "keys = []\n",
    "values = []\n",
    "\n",
    "for key,value in b.items() :\n",
    "    if value > 500 and key != \"\":\n",
    "        keys.append(key)\n",
    "        values.append(value)\n",
    "\n",
    "       \n",
    "labels = keys\n",
    "colors = sns.color_palette()\n",
    "explode = [0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "sizes = values\n",
    "    \n",
    "plt.figure(figsize = (20,12))\n",
    "\n",
    "plt.pie(sizes,explode = explode,labels = labels,colors = colors,autopct = '%1.1f%%',textprops = {\"fontsize\": 20},shadow = False)\n",
    "plt.title(\"Number of Movies produced by a Country\", fontsize = 20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph 2: Number of Each Movie Genres "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 884
    },
    "id": "RlPsIX3CxJ6P",
    "outputId": "1a46061d-b075-4a62-f609-164c21f3f310"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "data = df_raw.genres.copy()\n",
    "\n",
    "list_kind = data.str.split(\",\")\n",
    "a = []\n",
    "for each in list_kind:\n",
    "    for i in each:\n",
    "        a.append(i)\n",
    "        \n",
    "c=[]\n",
    "for each in a:\n",
    "    if each != \"\":\n",
    "         c.append(each)        \n",
    "        \n",
    "f= dict(Counter(c))\n",
    "\n",
    "df3 = pd.DataFrame(list(f.items()),columns = [\"kind\",\"ratio\"])\n",
    "new_index =( df3.ratio.sort_values(ascending=False)).index.values\n",
    "new = df3.reindex(new_index)\n",
    "\n",
    "plt.figure( figsize = (20,12))\n",
    "plt.tick_params(labelsize = 15)\n",
    "sns.barplot(x=\"kind\",y=\"ratio\",data=new,palette = sns.cubehelix_palette(len(f)))\n",
    "plt.xticks(rotation = 90)\n",
    "plt.xlabel(\"Kind Of Movie\",fontsize=20)\n",
    "plt.ylabel(\"Count\",fontsize=20)\n",
    "plt.title(\"Number of Each Movie Genres\",fontsize = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph 3: Count Each Type of Movie Ratings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 681
    },
    "id": "AJq8upFtPHyc",
    "outputId": "203cc232-68a6-4cb2-a631-c5af4ac29243"
   },
   "outputs": [],
   "source": [
    "f,ax = plt.subplots(1,1,figsize=(20,12))\n",
    "ax = sns.countplot(x=\"rating\", data=ratings_updated_df)\n",
    "ax.set_yticklabels([num for num in ax.get_yticks()])\n",
    "plt.tick_params(labelsize = 15)\n",
    "plt.title(\"Count Each Type of Movie Ratings \", fontsize = 20)\n",
    "plt.xlabel(\"Ratings\", fontsize = 20)\n",
    "plt.ylabel(\"Number of Ratings\", fontsize = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph 4: Most Popular Movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 649
    },
    "id": "dG9e6kv4QTlr",
    "outputId": "9decfa43-467c-41b5-ca3f-4574a27b8c28"
   },
   "outputs": [],
   "source": [
    "pop = df_raw.sort_values('popularity', ascending=False)\n",
    "plt.figure(figsize=(20,12))\n",
    "\n",
    "plt.barh(pop['title'].head(6),pop['popularity'].head(6), align='center',\n",
    "        color='skyblue')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tick_params(labelsize = 15)\n",
    "plt.xlabel(\"Popularity\", fontsize = 20)\n",
    "plt.ylabel(\"The title of movie\", fontsize = 20)\n",
    "plt.title(\"Most Popular Movies\", fontsize = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph 5: Top 6 movies with highest revenue compared to its budget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 865
    },
    "id": "h5Faf59PT1Zg",
    "outputId": "567feb0e-b900-4d64-e877-e2223ce145de"
   },
   "outputs": [],
   "source": [
    "df1 = movies_df[['title','revenue','budget']].copy()\n",
    "\n",
    "df1.set_index('title', inplace=True)\n",
    "\n",
    "ax = df1.sort_values(by=['revenue'], ascending=False).head(6).plot(kind='bar', figsize=(20,12))\n",
    "ax.xaxis.set_major_formatter(plt.FixedFormatter(df1.index.to_series()))\n",
    "plt.tick_params(labelsize = 15)\n",
    "plt.ylabel(\"Ammount of money in billion ($)\", fontsize = 20)\n",
    "plt.xlabel(\"The title of movie\", fontsize = 20)\n",
    "plt.legend(fontsize=20)\n",
    "plt.title(\"Top 6 movies with highest revenue compared to its budget\", fontsize = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chart 6: Most popular Language in Movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 728
    },
    "id": "iIn2-_SIENZs",
    "outputId": "6b5c995b-68dd-4a22-848b-f5a02c2f76ad"
   },
   "outputs": [],
   "source": [
    "unique = list(df_raw.original_language.unique())\n",
    "list_ratio=[]\n",
    "for each in unique:\n",
    "    x= movies_df[movies_df[\"original_language\"] == each]\n",
    "    ratio_popularity=sum(x.popularity)/len(x)\n",
    "    list_ratio.append(ratio_popularity)\n",
    "    \n",
    "df1 = pd.DataFrame({\"language\":unique,\"ratio\":list_ratio})\n",
    "new_index = (df1.ratio.sort_values(ascending = False).head(6)).index.values\n",
    "sorted_data= df1.reindex(new_index)\n",
    "\n",
    "#Visualization\n",
    "plt.figure(figsize = (20,12))\n",
    "sns.barplot(x= sorted_data[\"language\"],y  = sorted_data[\"ratio\"])\n",
    "plt.xticks(rotation= 90)\n",
    "plt.tick_params(labelsize = 15)\n",
    "\n",
    "plt.xlabel(\"Language\",fontsize = 20)\n",
    "plt.ylabel(\"Popularity\",fontsize = 20)\n",
    "plt.title(\"Most popular Language in Movies\", fontsize = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0vxC5GbVmVNw"
   },
   "source": [
    "# 2. Data Modelling\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-etfxnQnTnJZ"
   },
   "source": [
    "## 2.1 Feature Engineering\n",
    "\n",
    "Feature selection for fitting into the machine learning algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_updated.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dFIad3f11IO-"
   },
   "source": [
    "#### 2.1.1 Reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_updated['adult'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because column 'adult' only contains 1 value (False), we can remove this feature from the dataset. Also, from a reality perspective, we can also drop other columns that does not predict the rating of a movies:\n",
    "- imdb_id: id of the movie on imdb film review site\n",
    "- movieId: id of the movie in the dataset\n",
    "- poster_path: url to the poster of the movie\n",
    "- original_title, title: name of the movie before and after release\n",
    "- overview: a brief description about the movie\n",
    "- tagline: the movie quote (usually in posters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_updated.drop(['adult','imdb_id','poster_path','title','original_title','overview','movieId','tagline'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_column = df_updated.pop('rating')\n",
    "df_updated.insert(0, 'rating', first_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_updated['rating'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3TIDlRQG_7i_"
   },
   "source": [
    "#### 2.1.2 Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 782
    },
    "id": "21xLwbjn8mu7",
    "outputId": "8a7d7e2f-9c80-4841-eb35-fbe43eb3cdc4"
   },
   "outputs": [],
   "source": [
    "f,ax = plt.subplots(figsize = (20,12))\n",
    "sns.heatmap (df_updated.corr(), annot = True,linewidths =0.75,linecolor = \"White\",fmt = \".2f\",ax = ax,center = -0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VaUxAwxemG8Q"
   },
   "source": [
    "### 2.2 Train/Test/Val Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s9JNw-RfmB7L"
   },
   "outputs": [],
   "source": [
    "train_size = 0.8\n",
    "valid_size = 0.1\n",
    "\n",
    "train_index = int(len(df_updated)*train_size)\n",
    "\n",
    "df_updated_train = df_updated[0:train_index]\n",
    "df_updated_rem = df_updated[train_index:]\n",
    "\n",
    "valid_index = int(len(df_updated)*valid_size)\n",
    "\n",
    "df_updated_valid = df_updated[train_index:train_index+valid_index]\n",
    "df_updated_test = df_updated[train_index+valid_index:]\n",
    "\n",
    "X_train, y_train = df_updated_train.drop(columns='rating').copy(), df_updated_train['rating'].copy()\n",
    "X_valid, y_valid = df_updated_valid.drop(columns='rating').copy(), df_updated_valid['rating'].copy()\n",
    "X_test, y_test = df_updated_test.drop(columns='rating').copy(), df_updated_test['rating'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tZBxUX3AUQ74"
   },
   "source": [
    "### 2.3 Parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt import BayesSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameter Tunning for Decision Tree Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i4FnYlxhUpbx"
   },
   "outputs": [],
   "source": [
    "n_iter = 20\n",
    "\n",
    "paramDT = {\n",
    "    'max_depth' : [3,5,7,9,10,15,20,25],\n",
    "    'criterion' : ['gini', 'entropy'],\n",
    "    'max_features' : ['auto', 'sqrt', 'log2'],\n",
    "    'min_samples_split' : [2,4,6]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameter Tunning for Light GBM Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramLGBM = {\n",
    "    'num_leaves':[20,40,60,80,100], \n",
    "    'min_child_samples':[5,10,15],\n",
    "    'max_depth':[-1,5,10,20],\n",
    "    'learning_rate':[0.05,0.1,0.2],\n",
    "    'reg_alpha':[0,0.01,0.03]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameter Tunning for XG Boost Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramXGBR = { \n",
    "    'max_depth': [3, 5, 6, 10, 15, 20],\n",
    "    'learning_rate': [0.01, 0.1, 0.2, 0.3],\n",
    "    'subsample': np.arange(0.5, 1.0, 0.1),\n",
    "    'colsample_bytree': np.arange(0.4, 1.0, 0.1),\n",
    "    'colsample_bylevel': np.arange(0.4, 1.0, 0.1),\n",
    "    'n_estimators': [100, 500, 1000]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yIMV5lbEUXXE"
   },
   "source": [
    "### 2.4 Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 1: Using Decision Tree Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qyrU1zmAUp7q"
   },
   "outputs": [],
   "source": [
    "# DT_searchCV  = BayesSearchCV(\n",
    "#         estimator = DecisionTreeClassifier(random_state=42),\n",
    "#         search_spaces = paramDT,\n",
    "#         n_jobs = -1,\n",
    "#         cv = 3,\n",
    "#         n_iter  = n_iter,\n",
    "#         scoring = \"accuracy\",\n",
    "#         verbose = 4,\n",
    "#         random_state = 42\n",
    "# )\n",
    "# DT_searchCV.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DT_searchCV.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best params for this algorithm:\n",
    "{\n",
    "    'max_depth': 15,\n",
    "    'max_features': 'auto',\n",
    "    'random_state': 42\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(max_depth=15, max_features='auto', random_state=42)\n",
    "dt.fit(X_train, y_train)\n",
    "y_predict_dt = dt.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 2: Using LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm = lgb.LGBMClassifier(random_state=42)\n",
    "# LGBM_searchCV = RandomizedSearchCV(\n",
    "#     estimator = lgb,\n",
    "#     param_distributions = paramLGBM,\n",
    "#     n_jobs = -1,\n",
    "#     scoring = 'accuracy',\n",
    "#     n_iter = 20,\n",
    "#     random_state=42\n",
    "# )\n",
    "# LGBM_searchCV.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LGBM_searchCV.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Parameters for this algorithm:\n",
    "{'reg_alpha': 0.03,\n",
    " 'num_leaves': 20,\n",
    " 'min_child_samples': 15,\n",
    " 'max_depth': 5,\n",
    " 'learning_rate': 0.05}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_params = {\n",
    "'reg_alpha': 0.03,\n",
    " 'num_leaves': 20,\n",
    " 'min_child_samples': 15,\n",
    " 'max_depth': 5,\n",
    " 'learning_rate': 0.05,\n",
    " 'random_state':42\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set optimal parameters\n",
    "lgbm.set_params(**lgbm_params)\n",
    "lgbm.fit(X_train, y_train)\n",
    "y_predict_lgbm = lgbm.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 3: Using XGBoost Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbr = xgb.XGBClassifier(random_state=42)\n",
    "# XGBR_searchCV = RandomizedSearchCV(\n",
    "#     estimator = xgbr,\n",
    "#     param_distributions = paramXGBR,\n",
    "#     scoring = 'accuracy',\n",
    "#     n_iter = 10,\n",
    "#     n_jobs = -1,\n",
    "#     random_state=42\n",
    "# )\n",
    "\n",
    "# XGBR_searchCV.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBR_searchCV.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Parameters for this algorithm:\n",
    "{\n",
    "    'subsample': 0.8999999999999999,\n",
    "    'n_estimators': 100,\n",
    "    'max_depth': 6,\n",
    "    'learning_rate': 0.1,\n",
    "    'colsample_bytree': 0.5,\n",
    "    'colsample_bylevel': 0.8999999999999999\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbr_params = {\n",
    "    'subsample': 0.8999999999999999,\n",
    "    'n_estimators': 100,\n",
    "    'max_depth': 6,\n",
    "    'learning_rate': 0.1,\n",
    "    'colsample_bytree': 0.5,\n",
    "    'colsample_bylevel': 0.8999999999999999,\n",
    "    'random_state':42\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbr.set_params(**xgbr_params)\n",
    "xgbr.fit(X_train, y_train)\n",
    "y_predict_xgbr = xgbr.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I7bYQMaJUcbP"
   },
   "source": [
    "### 2.5 Model Evaluation and Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ch9aUt7BUzex"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 1: Using Decision Tree Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_rmse = np.sqrt(mean_squared_error(y_test, y_predict_dt))\n",
    "dt_mae = mean_absolute_error(y_test, y_predict_dt)\n",
    "dt_r2 = r2_score(y_test, y_predict_dt)\n",
    "dt_accuracy = accuracy_score(y_test, y_predict_dt)\n",
    "\n",
    "print('RMSE: ', dt_rmse)\n",
    "print('MAE: ', dt_mae)\n",
    "print('R2: ', dt_r2)\n",
    "print('Accuracy: ', dt_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 2: Using LightGBM Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_rmse = np.sqrt(mean_squared_error(y_test, y_predict_lgbm))\n",
    "lgbm_mae = mean_absolute_error(y_test, y_predict_lgbm)\n",
    "lgbm_r2 = r2_score(y_test, y_predict_lgbm)\n",
    "lgbm_accuracy = accuracy_score(y_test, y_predict_lgbm)\n",
    "\n",
    "print('RMSE: ', lgbm_rmse)\n",
    "print('MAE: ', lgbm_mae)\n",
    "print('R2: ', lgbm_r2)\n",
    "print('Accuracy: ', lgbm_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 3: Using XGBoost Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbr_rmse = np.sqrt(mean_squared_error(y_test, y_predict_xgbr))\n",
    "xgbr_mae = mean_absolute_error(y_test, y_predict_xgbr)\n",
    "xgbr_r2 = r2_score(y_test, y_predict_xgbr)\n",
    "xgbr_accuracy = accuracy_score(y_test, y_predict_xgbr)\n",
    "\n",
    "print('RMSE: ', xgbr_rmse)\n",
    "print('MAE: ', xgbr_mae)\n",
    "print('R2: ', xgbr_r2)\n",
    "print('Accuracy: ', xgbr_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_metric = {\n",
    "    'Model': ['Decision Tree Algorithm', 'Light GBM Algorithm', 'XG Boost ALgorithm'],\n",
    "    'RMSE': [dt_rmse,lgbm_rmse , xgbr_rmse],\n",
    "    'MAE': [dt_mae, lgbm_mae, xgbr_mae],\n",
    "    'R2': [dt_r2, lgbm_r2, xgbr_r2],\n",
    "    'Accuracy': [dt_accuracy,lgbm_accuracy,xgbr_accuracy]\n",
    "}\n",
    "model_df = pd.DataFrame(data = model_metric)\n",
    "model_df.style.background_gradient().hide_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eFVIr1YGUiDN"
   },
   "source": [
    "### 2.6 Save the model for deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r_72FnWrVInB"
   },
   "source": [
    "In this task, we use Pickle to save and load the model. Since in order to use the model outside of the notebook, we need to sae it - and then later, we can load and use it for deployment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VG1n4a4vUqv0"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(xgbr, open('xgbr.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l0NXFF_uUyjh"
   },
   "source": [
    "## 3. Model deployment and Automation\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please use Postman in order to do below step:\n",
    " - Create new POST request to http://127.0.0.1:5000/evaluate or http://127.0.0.1:5000/predict\n",
    "  - Body:\n",
    "    - formdata:\n",
    "      - key : file\n",
    "      - type: file\n",
    "      - value: choose file data.csv in \"test\" folder\n",
    " - Evaluate API: http://127.0.0.1:5000/evaluate to output the evaluation metric\n",
    " - PRedict API http://127.0.0.1:5000/predict to output the predicted rating value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xJXq5JmKU1eP"
   },
   "source": [
    "## 4. Visualisation Dashboard\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For starting the visualization dashboard:\n",
    " - Go inside folder \"movie-rating-prediction'\n",
    " - Run python dashboard.py\n",
    " - Wait until  this line \"Running on http://127.0.0.1:5000/\" appear\n",
    " - Navigate to this URL to see the visualization dashboard"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "assignment3.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
